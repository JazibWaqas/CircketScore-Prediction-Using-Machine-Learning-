#!/usr/bin/env python3
"""
Fix Data Leakage in Training Dataset
Remove post-match features that cause data leakage
"""

import pandas as pd
import numpy as np

def fix_data_leakage():
    """Remove data leakage features from training dataset"""
    print("ğŸ”§ FIXING DATA LEAKAGE IN TRAINING DATASET")
    print("=" * 60)
    
    # Load the original training dataset
    try:
        train_df = pd.read_csv('data/simple_enhanced_train.csv')
        print(f"âœ… Loaded original dataset: {train_df.shape}")
    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        return
    
    # Identify data leakage features (post-match information)
    data_leakage_features = [
        'match_winner',      # Who won the match
        'player_of_match',   # Who was player of the match
        'is_final',          # Whether it was a final (could be derived from context)
        'is_semi_final',     # Whether it was a semi-final
    ]
    
    # Check which features actually exist in the dataset
    existing_leakage_features = [col for col in data_leakage_features if col in train_df.columns]
    
    print(f"\nğŸš¨ DATA LEAKAGE FEATURES FOUND:")
    for feature in existing_leakage_features:
        print(f"  âŒ {feature}")
        if feature == 'match_winner':
            print(f"      Values: {train_df[feature].value_counts().head()}")
    
    # Create cleaned dataset
    print(f"\nğŸ§¹ CREATING CLEANED DATASET:")
    
    # Remove data leakage features
    cleaned_df = train_df.drop(columns=existing_leakage_features)
    
    print(f"  Removed {len(existing_leakage_features)} data leakage features")
    print(f"  Original shape: {train_df.shape}")
    print(f"  Cleaned shape: {cleaned_df.shape}")
    
    # Check for any other potentially suspicious features
    print(f"\nğŸ” CHECKING FOR OTHER POTENTIAL ISSUES:")
    
    # Features that might contain future information
    suspicious_patterns = ['result', 'outcome', 'final_score', 'actual_score']
    suspicious_features = []
    
    for col in cleaned_df.columns:
        if any(pattern in col.lower() for pattern in suspicious_patterns):
            suspicious_features.append(col)
    
    if suspicious_features:
        print(f"  âš ï¸ Potentially suspicious features: {suspicious_features}")
    else:
        print(f"  âœ… No other suspicious features found")
    
    # Verify the target variable is still present
    if 'total_runs' in cleaned_df.columns:
        print(f"  âœ… Target variable 'total_runs' preserved")
        print(f"      Mean: {cleaned_df['total_runs'].mean():.1f}")
        print(f"      Std: {cleaned_df['total_runs'].std():.1f}")
    else:
        print(f"  âŒ ERROR: Target variable 'total_runs' missing!")
        return
    
    # Save the cleaned dataset
    output_file = 'data/simple_enhanced_train_cleaned.csv'
    cleaned_df.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ SAVED CLEANED DATASET:")
    print(f"  File: {output_file}")
    print(f"  Shape: {cleaned_df.shape}")
    
    # Create a summary of what was removed
    removal_summary = {
        'original_features': len(train_df.columns),
        'cleaned_features': len(cleaned_df.columns),
        'removed_features': len(existing_leakage_features),
        'removed_feature_names': existing_leakage_features,
        'target_variable_preserved': 'total_runs' in cleaned_df.columns,
        'rows_preserved': len(cleaned_df)
    }
    
    print(f"\nğŸ“‹ REMOVAL SUMMARY:")
    print(f"  Original features: {removal_summary['original_features']}")
    print(f"  Cleaned features: {removal_summary['cleaned_features']}")
    print(f"  Removed features: {removal_summary['removed_features']}")
    print(f"  Rows preserved: {removal_summary['rows_preserved']}")
    
    # Check feature correlations with target after cleaning
    print(f"\nğŸ“ˆ FEATURE-TARGET CORRELATIONS (AFTER CLEANING):")
    
    numeric_features = cleaned_df.select_dtypes(include=[np.number]).columns
    correlations = cleaned_df[numeric_features].corr()['total_runs'].abs().sort_values(ascending=False)
    
    print(f"  Top 10 features correlated with total_runs:")
    for feature, corr in correlations.head(11).items():
        if feature != 'total_runs':
            print(f"    {feature}: {corr:.3f}")
    
    # Compare with original correlations
    print(f"\nğŸ” CORRELATION COMPARISON:")
    original_correlations = train_df[numeric_features].corr()['total_runs'].abs().sort_values(ascending=False)
    
    print(f"  Original top 3 correlations:")
    for feature, corr in original_correlations.head(4).items():
        if feature != 'total_runs':
            print(f"    {feature}: {corr:.3f}")
    
    print(f"  Cleaned top 3 correlations:")
    for feature, corr in correlations.head(4).items():
        if feature != 'total_runs':
            print(f"    {feature}: {corr:.3f}")
    
    return {
        'cleaned_df': cleaned_df,
        'removal_summary': removal_summary,
        'output_file': output_file
    }

if __name__ == "__main__":
    result = fix_data_leakage()
    
    print(f"\n" + "="*60)
    print("NEXT STEPS")
    print("="*60)
    print(f"1. âœ… Data leakage removed from training dataset")
    print(f"2. ğŸ”„ Retrain models with cleaned dataset")
    print(f"3. ğŸ§ª Test model accuracy on cleaned data")
    print(f"4. ğŸ“Š Compare performance before/after cleaning")
    print(f"5. ğŸ¯ Use cleaned models for real predictions")
    
    if result:
        print(f"\nğŸ“ Cleaned dataset saved to: {result['output_file']}")
        print(f"   Ready for retraining models without data leakage!")
